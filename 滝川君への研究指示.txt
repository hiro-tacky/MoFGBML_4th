複数のメンバーシップ関数形状が利用可能なMoFGBMLの開発
実験２では，メンバーシップ関数の形状が識別性能に与える影響を調査した．その拡張として複数のメンバーシップ関数形状を同時に用いた識別器設計を行う．

ステップ１：MoFGBMLの改良
改良点１．パターンからのルール生成．
従来のFGBMLでは，１種類の形状のメンバーシップ関数候補（2〜5分割，14個）から，選択されたパターンの各属性値に対して適合度の高いメンバーシップ関数を確率的に選択している．この候補を複数種類の形状に拡張する．すなわち，三角型，区間型，台形型，ガウシアン型の計64個のメンバーシップ関数に対して適合度を計算し，より適合するメンバーシップ関数を確率的に選択する．
＊初期化の部分とミシガン操作時の誤識別パターンからのルール生成で利用．

改良点２．突然変異
従来のFGBMLでは，突然変異により１種類の形状のメンバーシップ関数候補（2〜5分割計14個+don't care）のいずれかのメンバーシップ関数に置き換えられている（同じメンバーシップ関数は除く）．この候補を複数種類の形状に拡張する．単純に（ルール生成と同様に）64個から選ぶとなると適した	メンバーシップ関数が選ばれる可能性はかなり低い．そこで，突然変異が適用される属性に対して，さらに1/2の確率で同じ種類のメンバーシップ関数形状から選択（14個から選ぶ）し，残り1/2の確率で異なる形状に変更する（3種類）．後者の操作は，もし突然変異を適用する属性に三角型メンバーシップ関数の2分割のSmallが使われていたら，突然変異によって，区間型あるいは台形型あるいはガウシアン型の２分割のSmallに置き換えるという方法である．

実は，通常のFGBMLでも突然変異によって，全然適していないメンバーシップ関数に変更されている可能性がある．もう少し丁寧に，同じ分割数の隣のメンバーシップに変更するとか，異なる分割数だけど同じような位置にあるメンバーシップ関数に変更するなどの局所探索的な突然変異の方が良い可能性がある．これはこれで別途調査すべき課題である．（Jorge Casillasがこの手の突然変異を既に提案しているので新規性はないので，もし我々のFGBMLでも効果があるようであれば，デフォルトで導入すべきかもしれない）

ステップ２：人工データを用いた実験
適当に分布を仮定した２次元のデータをいろいろと作成し，改良の効果をみる．このとき，識別性能と識別境界を比較しよう．
なお，単一形状のメンバーシップ関数を用いる場合よりも探索空間が広くなるので，最適化の速度は（大幅に）落ちると思われる．このことも念頭にいれておいて，100世代後の結果，1000世代後の結果，10000世代後の結果，100000世代後の結果というように，複数世代の結果を一度に書き出せるようにしておこう．

なお．この実験では良いところが何も出ない可能性があるが，くじけないように．

ステップ３：UCIデータを用いた実験１
小規模データ（1000パターン以下）を3〜5個程度選んで実験を回してみる．

ステップ４：UCIデータを用いた実験２
大規模データ（1000パターン以上，50000パターン以下）を数個選んで実験を回してみる．

ステップ５：UCIデータを用いた実験３
小規模データから大規模データまで20〜30個程度選んで実験を回す．

数値実験では，学習用データおよび評価用データに対する非劣解の図示と，学習用データに対して最も識別率が高い個体を選んで，学習用データに対する識別率，評価用データに対する識別率，ルール数をまとめた表の作成を行う．

結構手間なので，可能な限り自動化しよう．
